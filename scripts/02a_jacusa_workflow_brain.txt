#! /bin/bash

# This workflow takes fastq files from the acta-neuropath data and runs them through alignment and editing:

# Find filenames to add in to SampleAnnot:
ml parallel/20230722-GCCcore-12.2.0
parallel find . -name "'*{}*R1_001_QC.fastq.gz'" ::: PDC05 PDC22 PDC34 PDC87 PDC91 PD115 PD163 PD294 PD332 PD566 PD706 PD413 PD416 PD523 PD666 PD683 PD732 PD747 PD341 PD366 PD415 PD531 PD563 PD678

# First pass star alignment

### Run first pass star


cd /camp/home/wagena/AIediting/raw_data/acta_neuropath_bulk/

tail -n+2 SampleAnnot.txt | parallel -kj1 --col-sep "\t" 'sbatch --parsable --export=sample={2},R1=QC/fastp/{1}_R1_001_QC.fastq.gz,R2=QC/fastp/{1}_R3_001_QC.fastq.gz,index=/camp/home/wagena/gandhis/home/users/wagena/references/GRCh38/index/star/hg38.93_sjdboverhang149,bamdir=/camp/home/wagena/gandhis/home/users/wagena/AIediting/raw_data/acta_neuropath_bulk/editing/star ~/scripts/star_first_pass.sh' >> jobs

# To check parallel is running correctly: tail -n+0 SampleAnnot.txt |
# parallel -kj1 --col-sep "\t" 'echo the sample was{1} and is now {2}'

## FLAG SUMMARY
# --outSAMattributesMD is crucial here for JACUSA to be run efficiently
#   (if don't have this then JACUSA needs to run this itself with the fasta
#   file. In hisat this is run with samtools calmd) intronMotif - adds some
#   utility calling the strand of a transcript over a splice junction. George
#   adds this as defauly.
# --outStd - 'standard out' sends the output to pipe. If want to use this
#   option need a piped output to follow
# --outReadsUnmapped Fastx ", # output in separate fast/fastq files the
#   unmapped/partially-mapped reads
# --outSAMtype BAM SortedByCoordinate ", # output as a sorted BAM,
# --outFilterType BySJout ", # removes spurious split reads
# --outFilterMultimapNmax 1 ", # only allows reads to be mapped to one
#   position in the genome
# --outFilterMismatchNmax 999 ", # Maximum number of mismatches per pair.
#   Large numbers switch off filter. Instead we filter
#   by "--outFilterMismatchNoverReadLmax".
# --outFilterMismatchNoverReadLmax 0.16 is defauly. We are using 0.16 to not
#   exlclude edits of interest
# --alignIntronMin 20 ", # min intron length. As per ENCODE options.
# --alignIntronMax 1000000 ", # max intron length. As per ENCODE options
#   (currently from ensembl its 1,097,903 from KCNIP4).
# --alignMatesGapMax 1000000 ", # max gap between pair mates. As per ENCODE
#   options.
# --alignSJoverhangMin 8 ", # minimum unannotated split read anchor. As per
#   ENCODE options.
# --alignSJDBoverhangMin 3 " # minimum annotated split read anchor. Default is
#   3. This is the whole purpose of using 2 passes, to allow previously
#   unnanotated junctions to be considered annotated.

#Flags used: STAR \
#--runThreadN 32 \
#--genomeDir ${index} \
#--readFilesIn ${R1} ${R2} \
#--outSAMattributes NH HI AS nM NM MD \
#--readFilesCommand zcat \
#--outFileNamePrefix "${bamdir}/${sample}_" \
#--outReadsUnmapped Fastx \
#--outSAMstrandField intronMotif \
#--outFilterType BySJout \
#--outFilterMultimapNmax 1 \
#--outFilterMismatchNmax 999 \
#--outFilterMismatchNoverReadLmax 0.16 \
#--alignIntronMin 20 \
#--alignIntronMax 1000000 \
#--alignMatesGapMax 1000000 \
#--alignSJoverhangMin 8 \
#--alignSJDBoverhangMin 3


### Filter split junction files

cat *.tab | awk '($5 > 0 && $7 > 2 && $6==0)' | cut -f1-6 | sort | uniq > SJ.filtered.tab

# This filters out:
# - non canonical junctions (column 5 >0)
# - junctions supported by multimappers only (column 7 >0)
# - columns supported by too few reads (column 7>2)
# - remove annotated junctions as these are always included from the GTF
#   (column 6==0)
# - sort the columns and remove duplicates (sort and uniq)



### Run second pass star and samtools

tail -n+2 SampleAnnot.txt | parallel -kj1 --col-sep "\t" 'sbatch --parsable --export=sample={2},R1=/camp/home/wagena/AIediting/raw_data/acta_neuropath_bulk/QC/fastp/{1}_R1_001_QC.fastq.gz,R2=/camp/home/wagena/AIediting/raw_data/acta_neuropath_bulk/QC/fastp/{1}_R3_001_QC.fastq.gz,index=/camp/home/wagena/gandhis/home/users/wagena/references/GRCh38/index/star/hg38.93_sjdboverhang149,bamdir=/camp/home/wagena/gandhis/home/users/wagena/AIediting/raw_data/acta_neuropath_bulk/editing/star ~/scripts/star_samtools_markdup.sh' >> jobs

#
##### RUNNING JACUSA DETECT
#

#
### Run JACUSA detect collapsing the grouped samples
#

mkdir jacusa_detect

cd star

# Find files in same group and split them by a comma:

# Eg use the following command to fine the files and concatenote them by
# comma
find control_?_Aligned_fix_sort_markdup_calmd.bam | tr '\n' ','
find PD_?_Aligned_fix_sort_markdup_calmd.bam | tr '\n' ','
find PDD_?_Aligned_fix_sort_markdup_calmd.bam | tr '\n' ','
find DLB_?_Aligned_fix_sort_markdup_calmd.bam | tr '\n' ','

# This can be further automated by find
# astro_asyn_?_?_Aligned_fix_sort_markdup_calmd.bam | tr '\n' ',' >
# astro_asyn_files though then would need to find a way to call this text
# filein jacusa

control_samples="control_1_Aligned_fix_sort_markdup_calmd.bam,control_2_Aligned_fix_sort_markdup_calmd.bam,control_3_Aligned_fix_sort_markdup_calmd.bam,control_4_Aligned_fix_sort_markdup_calmd.bam,control_5_Aligned_fix_sort_markdup_calmd.bam"
PD_samples="PD_1_Aligned_fix_sort_markdup_calmd.bam,PD_2_Aligned_fix_sort_markdup_calmd.bam,PD_3_Aligned_fix_sort_markdup_calmd.bam,PD_4_Aligned_fix_sort_markdup_calmd.bam,PD_5_Aligned_fix_sort_markdup_calmd.bam,PD_6_Aligned_fix_sort_markdup_calmd.bam,PD_7_Aligned_fix_sort_markdup_calmd.bam"
PDD_samples="PDD_1_Aligned_fix_sort_markdup_calmd.bam,PDD_2_Aligned_fix_sort_markdup_calmd.bam,PDD_3_Aligned_fix_sort_markdup_calmd.bam,PDD_4_Aligned_fix_sort_markdup_calmd.bam,PDD_5_Aligned_fix_sort_markdup_calmd.bam,PDD_6_Aligned_fix_sort_markdup_calmd.bam"
DLB_samples="DLB_1_Aligned_fix_sort_markdup_calmd.bam,DLB_2_Aligned_fix_sort_markdup_calmd.bam,DLB_3_Aligned_fix_sort_markdup_calmd.bam,DLB_4_Aligned_fix_sort_markdup_calmd.bam,DLB_5_Aligned_fix_sort_markdup_calmd.bam,DLB_6_Aligned_fix_sort_markdup_calmd.bam"


# Call this script from within the star folder
# Control
sbatch --parsable --ntasks=1 --job-name=jac_detect --cpus-per-task 16 --mem=128G --time=1-00:00:00 --wrap="bash /camp/home/wagena/AIediting/scripts/jacusa_detect_collapsing_samples.sh /camp/home/wagena/AIediting/raw_data/acta_neuropath_bulk/editing/jacusa_detect/control.jacusa ${control_samples}"

# PD
sbatch --parsable --ntasks=1 --job-name=jac_detect --cpus-per-task 16 --mem=128G --time=1-00:00:00 --wrap="bash /camp/home/wagena/AIediting/scripts/jacusa_detect_collapsing_samples.sh /camp/home/wagena/AIediting/raw_data/acta_neuropath_bulk/editing/jacusa_detect/PD.jacusa ${PD_samples}"

# PDD
sbatch --parsable --ntasks=1 --job-name=jac_detect --cpus-per-task 16 --mem=128G --time=1-00:00:00 --wrap="bash /camp/home/wagena/AIediting/scripts/jacusa_detect_collapsing_samples.sh /camp/home/wagena/AIediting/raw_data/acta_neuropath_bulk/editing/jacusa_detect/PDD.jacusa ${PDD_samples}"

# DLB
sbatch --parsable --ntasks=1 --job-name=jac_detect --cpus-per-task 16 --mem=128G --time=1-00:00:00 --wrap="bash /camp/home/wagena/AIediting/scripts/jacusa_detect_collapsing_samples.sh /camp/home/wagena/AIediting/raw_data/acta_neuropath_bulk/editing/jacusa_detect/DLB.jacusa ${DLB_samples}"



# Run jacusa_to_bed with no filters
ml Anaconda3
ml parallel/20230722-GCCcore-12.2.0
parallel -j4 --bar '/camp/home/wagena/AIediting/scripts/jacusa_2_bed.py -e AG -z 0 -d 1 -m 0 -s 1 {} > {.}.AG.bed 2> /dev/null' ::: *.jacusa



#
# RUN JACUSA DIFFERENTIAL
#

## Astro nt verse astro asyn
ml Java/13.0.2
cd star



# Note: java can't expand the bash flags for the different groups (control, pdd etc) so need to expand these out in bash prior, and then paste the complete list of control vs disease filenames in the commands below

# Control vs PD
echo ${control_samples} ${PD_samples}
sbatch --parsable --ntasks=1 --job-name=jac_differential --cpus-per-task 16 --mem=64G --time=1-00:00:00 --wrap="java -jar ~/bin/JACUSA_v2.0.2-RC.jar call-2 -p 16 -P FR-SECONDSTRAND -a D,Y -F 3852 -r /camp/home/wagena/AIediting/raw_data/acta_neuropath_bulk/editing/jacusa_differential/cont_vs_PD.jacusa control_1_Aligned_fix_sort_markdup_calmd.bam,control_2_Aligned_fix_sort_markdup_calmd.bam,control_3_Aligned_fix_sort_markdup_calmd.bam,control_4_Aligned_fix_sort_markdup_calmd.bam,control_5_Aligned_fix_sort_markdup_calmd.bam PD_1_Aligned_fix_sort_markdup_calmd.bam,PD_2_Aligned_fix_sort_markdup_calmd.bam,PD_3_Aligned_fix_sort_markdup_calmd.bam,PD_4_Aligned_fix_sort_markdup_calmd.bam,PD_5_Aligned_fix_sort_markdup_calmd.bam,PD_6_Aligned_fix_sort_markdup_calmd.bam,PD_7_Aligned_fix_sort_markdup_calmd.bam"


## Control vs PDD
echo ${control_samples} ${PDD_samples}
sbatch --parsable --ntasks=1 --job-name=jac_differential --cpus-per-task 16 --mem=64G --time=1-00:00:00 --wrap="java -jar ~/bin/JACUSA_v2.0.2-RC.jar call-2 -p 16 -P FR-SECONDSTRAND -a D,Y -F 3852 -r /camp/home/wagena/AIediting/raw_data/acta_neuropath_bulk/editing/jacusa_differential/cont_vs_PDD.jacusa control_1_Aligned_fix_sort_markdup_calmd.bam,control_2_Aligned_fix_sort_markdup_calmd.bam,control_3_Aligned_fix_sort_markdup_calmd.bam,control_4_Aligned_fix_sort_markdup_calmd.bam,control_5_Aligned_fix_sort_markdup_calmd.bam PDD_1_Aligned_fix_sort_markdup_calmd.bam,PDD_2_Aligned_fix_sort_markdup_calmd.bam,PDD_3_Aligned_fix_sort_markdup_calmd.bam,PDD_4_Aligned_fix_sort_markdup_calmd.bam,PDD_5_Aligned_fix_sort_markdup_calmd.bam,PDD_6_Aligned_fix_sort_markdup_calmd.bam"


# Control vs DLB
echo ${control_samples} ${DLB_samples}
sbatch --parsable --ntasks=1 --job-name=jac_differential --cpus-per-task 16 --mem=64G --time=1-00:00:00 --wrap="java -jar ~/bin/JACUSA_v2.0.2-RC.jar call-2 -p 16 -P FR-SECONDSTRAND -a D,Y -F 3852 -r /camp/home/wagena/AIediting/raw_data/acta_neuropath_bulk/editing/jacusa_differential/cont_vs_DLB.jacusa control_1_Aligned_fix_sort_markdup_calmd.bam,control_2_Aligned_fix_sort_markdup_calmd.bam,control_3_Aligned_fix_sort_markdup_calmd.bam,control_4_Aligned_fix_sort_markdup_calmd.bam,control_5_Aligned_fix_sort_markdup_calmd.bam DLB_1_Aligned_fix_sort_markdup_calmd.bam,DLB_2_Aligned_fix_sort_markdup_calmd.bam,DLB_3_Aligned_fix_sort_markdup_calmd.bam,DLB_4_Aligned_fix_sort_markdup_calmd.bam,DLB_5_Aligned_fix_sort_markdup_calmd.bam,DLB_6_Aligned_fix_sort_markdup_calmd.bam"





# Create VEP input files: use python script below or R script
cd AIediting/.../editing

bed_files=$(find jacusa_detect/*bed jacusa_differential/*bed) #Get a list of all relevant bed files
script="/camp/home/wagena/AIediting/scripts/create_vep_input_from_bed.py"
output="./vep/all_samples_vep.tsv"

python $script $output $bed_files


# Run VEP Use output in vcf mode

cd /camp/lab/gandhis/home/users/wagena/bin/ensembl-vep/

ml purge
ml Singularity/3.6.4


# Real command for VEP release 93.5
sbatch --time=12:00:00 --mem=64G --wrap='singularity exec --bind /camp ensembl-vep_release_93.5.sif vep --use_given_ref --dir /camp/lab/gandhis/home/users/wagena/bin/ensembl-vep/vep_data --cache --offline --force_overwrite --input_file /camp/home/wagena/AIediting/raw_data/acta_neuropath_bulk/editing/vep/all_samples_vep_input.tsv --output_file /camp/home/wagena/AIediting/raw_data/acta_neuropath_bulk/editing/vep/all_samples_vep_results_93_tab_flags --tab --sift b --polyphen b --canonical --check_ref --dont_skip --fasta /camp/home/wagena/AIediting/raw_data/astro_neuron_bulk/references/Homo_sapiens.GRCh38.dna.primary_assembly.fa --protein --biotype --af --max_af --tsl --check_existing --pubmed --buffer_size 20000 --warning_file /camp/home/wagena/AIediting/raw_data/acta_neuropath_bulk/editing/vep/all_samples_warning_file --gene_phenotype --numbers --symbol'



--buffer_size 20000
--gene_phenotype
--show_ref_allele
--numbers
--symbol
--ref_allele
--given_ref
--used_ref
--strand
--clin_sig
Note: check_ref not available for this version of vep



####
#
# Run JACUSA on individual samples
#
####

# Run JACUSA on uncollapsed samples (this uses a script that calls JACUSA in "FR_secondstrand" mode)
tail -n 24 SampleAnnot.txt | cut -f2 | parallel -kj1 'sbatch --parsable --export=EXAMPLE={} --output=/camp/home/wagena/gandhis/home/users/wagena/AIediting/raw_data/acta_neuropath_bulk/editing/jacusa_detect/{}.log /camp/home/wagena/gandhis/home/users/wagena/AIediting/raw_data/acta_neuropath_bulk/scripts/jacusa_detect_single_acta.sh' >> jobs

# Run jacusa_to_bed with no filters
ml Anaconda3
ml parallel
parallel -j4 --bar '/camp/home/wagena/AIediting/scripts/jacusa_2_bed.py -e AG -z 0 -d 1 -m 0 -s 1 {} > {.}.AG.bed 2> /dev/null' ::: *.jacusa

# Annotate with VEP
cd AIediting/.../editing

bed_files=$(find jacusa_collapsed/jacusa_detect/*bed jacusa_collapsed/jacusa_differential/*bed jacusa_detect/*bed) #Get a list of all relevant bed files
script="/camp/home/wagena/AIediting/scripts/create_vep_input_from_bed.py"
output="./vep/all_samples_vep.tsv"

conda activate python3.9_jupyter
python $script $output $bed_files


#
cd /camp/lab/gandhis/home/users/wagena/bin/ensembl-vep/

ml purge
ml Singularity


# Real command for VEP release 93.5 (The data from this paper was annotated with ensembl 93.5)
# Add in 'most severe' flag to vep to prevent requiring multiple manual filtering steps afterwards. Can't use this flag with --protein and --symbol, --polyphen, --sift, --canonical, --tsl
# Add in custom annotations with the reduced gtf and repeat regions in this step as well.

sbatch --time=12:00:00 --mem=64G --wrap='singularity exec --bind /nemo ensembl-vep_release_93.5.sif vep --use_given_ref --dir /nemo/lab/gandhis/home/users/wagena/bin/ensembl-vep/vep_data --cache --offline --force_overwrite --input_file /nemo/lab/gandhis/home/users/wagena/AIediting/raw_data/acta_neuropath_bulk/editing/vep/all_samples_vep.tsv --output_file /nemo/lab/gandhis/home/users/wagena/AIediting/raw_data/acta_neuropath_bulk/editing/vep/all_samples_vep_results_93_tab_flags_severe --most_severe --tab --check_ref --dont_skip --fasta /nemo/lab/gandhis/home/users/wagena/references/GRCh38/sequence/Homo_sapiens.GRCh38.dna.primary_assembly.fa --biotype --af --max_af --check_existing --pubmed --buffer_size 20000 --warning_file /nemo/lab/gandhis/home/users/wagena/AIediting/raw_data/acta_neuropath_bulk/editing/vep/all_samples_warning_file --gene_phenotype'






















